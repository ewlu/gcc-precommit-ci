name: Generate-Summary

on:
  workflow_call:
    inputs:
      patch_name:
        required: true
        type: string
      baseline_hash:
        required: true
        type: string
      patch_applied_gcchash:
        required: true
        type: string
      build_only:
        required: true
        type: string
      tot_hash:
        required: true
        type: string
      issue_num:
        required: true
        type: string
      build_comment_id:
        required: true
        type: string
      test_comment_id:
        required: true
        type: string
      additional_info:
        required: true
        type: string

  workflow_dispatch:
    branches:
      - patchworks-ci
    inputs:
      baseline_hash:
        description: 'GCC Hash'
        required: true
      patch_applied_gcchash:
        description: 'GCC Hash of applied commit'
        required: true
      patch_name:
        description: 'Patch name to regenerate summary for'
        required: true

jobs:
  compare-artifacts:
    if: ${{ always() && inputs.build_only != 'true' }} # ensure comparison always runs even on error
    runs-on: ubuntu-20.04
    environment: production
    defaults:
      run:
        working-directory: riscv-gnu-toolchain
    steps:
      - uses: actions/checkout@v4

      - name: Setup env
        uses: ./.github/actions/common/setup-env
        with:
          free_up_space: false

      - name: Check workflow dispatch
        id: dispatch
        if: ${{ inputs.tot_hash == '' }} # tot_hash always set at apply tip of tree step in run-checks.yaml
        run: |
          echo "workflow_dispatch=true" >> $GITHUB_OUTPUT

      - name: Create directories
        run: |
          mkdir current_logs
          mkdir temp
          mkdir summaries

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies
        run: |
          pip install -r ../requirements.txt

      - name: Download baseline sum files
        run: |
          # Download linux
          python ./scripts/download_artifact.py -name gcc-linux-rv64gcv-lp64d-${{ inputs.baseline_hash }}-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          python ./scripts/download_artifact.py -name gcc-linux-rv64gc_zba_zbb_zbc_zbs-lp64d-${{ inputs.baseline_hash }}-non-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          python ./scripts/download_artifact.py -name gcc-linux-rv32gc_zba_zbb_zbc_zbs-ilp32d-${{ inputs.baseline_hash }}-non-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          # Download newlib
          python ./scripts/download_artifact.py -name gcc-newlib-rv64gcv-lp64d-${{ inputs.baseline_hash }}-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          python ./scripts/download_artifact.py -name gcc-newlib-rv64gc-lp64d-${{ inputs.baseline_hash }}-non-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          python ./scripts/download_artifact.py -name gcc-newlib-rv32gc-ilp32d-${{ inputs.baseline_hash }}-non-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp
          python ./scripts/download_artifact.py -name gcc-newlib-rv64imc_zba_zbb_zbc_zbs-lp64d-${{ inputs.baseline_hash }}-multilib-sum-files -repo patrick-rivos/gcc-postcommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./temp

      - name: Replace allowlist
        run: |
          rm -rf test/
          cp -r ../test/ .

      - name: Extract and parse baseline results
        run: |
          mkdir -p previous_logs
          for file in $(find ./temp -name "*.zip"); do
            unzip $file
            if grep -q "linux" <<< $file; then
              PARSE_EXISTING_REPORT="./scripts/testsuite-filter gcc glibc test/allowlist `find sum_files -name *.sum |paste -sd "," -`"
            else
              PARSE_EXISTING_REPORT="./scripts/testsuite-filter gcc newlib test/allowlist `find sum_files -name *.sum |paste -sd "," -`"
            fi
            ZIP_NAME=${file##*/}
            FILE_NAME=${ZIP_NAME%%-multilib*}
            echo $FILE_NAME
            $PARSE_EXISTING_REPORT | tee "previous_logs/$FILE_NAME-multilib-report.log"
            rm -rf sum_files
          done
          ls previous_logs

      - name: Separate multilib results
        run: |
          python scripts/separate_multilib_results.py -indir previous_logs -outdir previous_logs
          ls previous_logs
        continue-on-error: true

      # Download all current workflow artifacts

      - name: Print API usage info
        run: |
          curl \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/rate_limit

      - name: Download All targets
        uses: ./.github/actions/download-all-comparison-artifacts
        with:
          gcchash: ${{ inputs.patch_applied_gcchash }}
          token: ${{ secrets.GITHUB_TOKEN }}
          repo: 'ewlu/gcc-precommit-ci'

      - name: Print API usage info
        run: |
          curl \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/rate_limit

      - name: Extract artifacts
        run: |
          ls ./temp/
          mkdir -p current_logs
          for f in $(ls ./temp/*report.zip); do
            unzip $f -d ./current_logs || true
          done
          ls current_logs

      - name: Separate multilib logs
        run: |
          python scripts/separate_multilib_results.py -indir current_logs -outdir current_logs
          mv current_logs/gcc-newlib-rv32imc_zba_zbb_zbc_zbs-ilp32-${{ inputs.patch_applied_gcchash }}-non-multilib-report.log current_logs/gcc-newlib-rv32imc_zba_zbb_zbc_zbs-ilp32-${{ inputs.patch_applied_gcchash }}-multilib-report.log
        continue-on-error: true

      - name: Compare artifacts
        run: |
          ls current_logs
          python ./scripts/compare_all_artifacts.py -hash ${{ inputs.patch_applied_gcchash }}

      - name: Search for build failures
        run: |
          python scripts/update_issue_status.py -token ${{ secrets.GITHUB_TOKEN }} -comment ${{ inputs.build_comment_id }} -repo ewlu/gcc-precommit-ci -failure -baseline ${{ inputs.baseline_hash }}
          ls current_logs
        continue-on-error: true

      - name: Remove testsuite failures on build-only
        if: ${{ inputs.build_only == 'true' }}
        run: |
          rm current_logs/failed_testsuite.txt
        continue-on-error: true

      - name: Upload compare summaries
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-summaries
          path: |
            riscv-gnu-toolchain/summaries
          retention-days: 90

      - name: Upload current log failures
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-current-logs
          path: |
            riscv-gnu-toolchain/current_logs
          retention-days: 90

      - name: Upload baseline results
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-previous-logs
          path: |
            riscv-gnu-toolchain/previous_logs
          retention-days: 90

      # Compare build warnings
      - name: Download patches artifact
        if: ${{ needs.compare-artifacts.outputs.workflow_dispatch == 'true' }}
        run: |
          mkdir patches
          python ./scripts/download_artifact.py -name ${{ inputs.patch_name }}-downloaded-patches -repo ewlu/gcc-precommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./patches
          ls patches

      - name: Download patches artifact
        if: ${{ needs.compare-artifacts.outputs.workflow_dispatch != 'true' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.patch_name }}-downloaded-patches
          path: ./riscv-gnu-toolchain/patches

      ################################################################################
      #    remove build log comparison stuff while we disable build-only runners     #
      ################################################################################

      # - name: Build Log Comparison Setup
      #   id: build-log-setup
      #   run: |
      #     mkdir -p previous_build_logs/build
      #     echo "previous_build_logs_path=$(readlink -f previous_build_logs)" >> $GITHUB_OUTPUT
      #     mkdir -p previous_build_log_zips
      #     echo "previous_build_log_zips_path=$(readlink -f previous_build_log_zips)" >> $GITHUB_OUTPUT
      #     mkdir -p current_build_logs/build
      #     echo "current_build_logs_path=$(readlink -f current_build_logs)" >> $GITHUB_OUTPUT
      #     mkdir -p current_build_log_zips
      #     echo "current_build_log_zips_path=$(readlink -f current_build_log_zips)" >> $GITHUB_OUTPUT
      #     mkdir build_warnings
      #     echo "build_warnings_directory=$(readlink -f ./build_warnings/)" >> $GITHUB_OUTPUT
      #     echo "new_build_warnings_path=$(readlink -f ./build_warnings/new_build_warnings.md)" >> $GITHUB_OUTPUT
      #     echo "resolved_build_warnings_path=$(readlink -f ./build_warnings/resolved_build_warnings.md)" >> $GITHUB_OUTPUT
      #     echo "patch_hash=$(tail -n 1 patches/${{ inputs.patch_name }})" >> $GITHUB_OUTPUT

      #
      # begin downloading current workflow build logs
      #

      # - name: Download Current linux rv64gc lp64d non multilib workflow build logs
      #   uses: ./.github/actions/common/download-build-log-artifact
      #   with:
      #     build-artifact-name: ${{ steps.build-log-setup.outputs.patch_hash }}-linux-rv64gc-lp64d-non-multilib-build-log
      #     github-token: ${{ secrets.GITHUB_TOKEN }}
      #     output-dir: ${{ steps.build-log-setup.outputs.current_build_log_zips_path }}
      #     repository: ewlu/gcc-precommit-ci

      # - name: Download Current newlib rv64gc lp64d non multilib Workflow build logs
      #   uses: ./.github/actions/common/download-build-log-artifact
      #   with:
      #     build-artifact-name: ${{ steps.build-log-setup.outputs.patch_hash }}-newlib-rv64gc-lp64d-non-multilib-build-log
      #     github-token: ${{ secrets.GITHUB_TOKEN }}
      #     output-dir: ${{ steps.build-log-setup.outputs.current_build_log_zips_path }}
      #     repository: ewlu/gcc-precommit-ci

      #TODO: Support Multilib. Restriction: https://github.com/ewlu/gcc-precommit-ci/pull/1919#discussion_r1686874053

      # - name: Unzip current build log artifacts
      #   uses: ./.github/actions/common/unzip-all-zips
      #   with:
      #     input-dir: ${{ steps.build-log-setup.outputs.current_build_log_zips_path }}
      #     output-dir: ${{ steps.build-log-setup.outputs.current_build_logs_path }}
      #     include-pattern: "*-stderr.log"
      # #
      # # begin downloading previous workflow build logs
      # #
      # - name: Download previous build log artifacts
      #   uses: ./.github/actions/download-all-build-log-artifacts
      #   with:
      #     gcchash: ${{ inputs.baseline_hash }}
      #     github-token: ${{ secrets.GITHUB_TOKEN }}
      #     output-dir: ${{ steps.build-log-setup.outputs.previous_build_log_zips_path }}

      # - name: Unzip previous build log artifacts
      #   id: unzip-previous-build-log-artifacts
      #   uses: ./.github/actions/common/unzip-all-zips
      #   with:
      #     input-dir: ${{ steps.build-log-setup.outputs.previous_build_log_zips_path }}
      #     output-dir: ${{ steps.build-log-setup.outputs.previous_build_logs_path }}
      #     include-pattern: "*-stderr.log"

      # - name: Parse Build Warnings
      #   id: parse-new-build-warnings
      #   run: |
      #     echo "build_log_exist=false" >> $GITHUB_OUTPUT
      #     python ./scripts/parse_build_warnings.py --old-dir ${{ steps.build-log-setup.outputs.previous_build_logs_path }}/build --new-dir ${{ steps.build-log-setup.outputs.current_build_logs_path }}/build --new-warnings-output ${{ steps.build-log-setup.outputs.new_build_warnings_path }} --resolved-warnings-output ${{ steps.build-log-setup.outputs.resolved_build_warnings_path }} --repo pre-commit
      #     if [ -f "${{ steps.build-log-setup.outputs.new_build_warnings_path }}" ]; then
      #       cat ${{ steps.build-log-setup.outputs.new_build_warnings_path }}
      #       echo "build_log_exist=true" >> $GITHUB_OUTPUT
      #     else
      #       echo "New build logs didn't exist"
      #     fi
      #     if [ -f "${{ steps.build-log-setup.outputs.resolved_build_warnings_path }}" ]; then
      #       cat ${{ steps.build-log-setup.outputs.resolved_build_warnings_path }}
      #       echo "build_log_exist=true" >> $GITHUB_OUTPUT
      #     else
      #       echo "Resolved build logs didn't exist"
      #     fi
      #   continue-on-error: true

      # - name: Upload Build Warnings
      #   if: ${{ steps.parse-new-build-warnings.outputs.build_log_exist == 'true' }}
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: ${{ steps.build-log-setup.outputs.patch_hash }}-build-warnings
      #     path: ${{ steps.build-log-setup.outputs.build_warnings_directory }}
      #     retention-days: 90

    outputs:
      baseline_hash: ${{ inputs.baseline_hash }}
      workflow_dispatch: ${{ steps.dispatch.outputs.workflow_dispatch }}

  generate-issues:
    if: ${{ always() && inputs.build_only != 'true' }} # ensure generate issues always runs even on error
    needs: [compare-artifacts]
    runs-on: ubuntu-20.04
    permissions:
      issues: write
    defaults:
      run:
        working-directory: riscv-gnu-toolchain
    steps:
      - uses: actions/checkout@v4

      - name: Setup env
        uses: ./.github/actions/common/setup-env
        with:
          free_up_space: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies
        run: |
          pip install -r ../requirements.txt

      - name: Download summaries artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-summaries
          path: ./riscv-gnu-toolchain/summaries

      - name: Download current logs artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-current-logs
          path: ./riscv-gnu-toolchain/current_logs

      - name: Download previous logs artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.patch_applied_gcchash }}-previous-logs
          path: ./riscv-gnu-toolchain/previous_logs

      # debug logs
      - name: Download linux rv64 bitmanip debug url artifact
        uses: actions/download-artifacts@v4
        with:
          name: gcc-linux-rv64gc_zba_zbb_zbc_zbs-lp64d-${{ inputs.patch_applied_gcchash }}-multilib-debug-url.md
          path: ./riscv-gnu-toolchain/
        continue-on-error: true

      - name: Download linux rv64 vector debug url artifact
        uses: actions/download-artifacts@v4
        with:
          name: gcc-linux-rv64gcv-lp64d-${{ inputs.patch_applied_gcchash }}-multilib-debug-url.md
          path: ./riscv-gnu-toolchain/
        continue-on-error: true

      - name: Download newlib rv64 vector debug url artifact
        uses: actions/download-artifacts@v4
        with:
          name: gcc-newlib-rv64gcv-lp64d-${{ inputs.patch_applied_gcchash }}-multilib-debug-url.md
          path: ./riscv-gnu-toolchain
        continue-on-error: true

      - name: Download patches artifact
        if: ${{ needs.compare-artifacts.outputs.workflow_dispatch == 'true' }}
        run: |
          mkdir patches
          python ./scripts/download_artifact.py -name ${{ inputs.patch_name }}-downloaded-patches -repo ewlu/gcc-precommit-ci -token ${{ secrets.GITHUB_TOKEN }} -outdir ./patches
          ls patches

      - name: Download patches artifact
        if: ${{ needs.compare-artifacts.outputs.workflow_dispatch != 'true' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.patch_name }}-downloaded-patches
          path: ./riscv-gnu-toolchain/patches

      - name: Print API usage info
        run: |
          curl \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/rate_limit

      - name: Aggregate information
        run: |
          python ./scripts/aggregate.py \
            -chash ${{ inputs.patch_applied_gcchash }} \
            -patch ${{ inputs.patch_name }} \
            -o temp_comment.md
          echo "## Testsuite Status" > comment.md
          tail -n+5 temp_comment.md >> comment.md
          cat comment.md

      - name: Print API usage info
        run: |
          curl \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/rate_limit

      - name: Trim comment length # reduce the number of lines in final comment so github always creates comment
        run: |
          # Max comment length is 65536. Allocate 1536 for extra statements
          head -c 64000 comment.md > trimmed_comment.md
          FILE_SIZE=$(stat -c%s "comment.md")
          if [ $FILE_SIZE -gt 64000 ]; then
            printf "\n\`\`\`\nComment text has been trimmed. Please check logs for the untrimmed comment." >> trimmed_comment.md;
            # Max gist bytes are 1048576. Allocate 576 for extra statements
            ONE_MB_IN_BYTES=1048000
            if [ $FILE_SIZE -gt $ONE_MB_IN_BYTES ]; then
              printf "\nThe file was greater than 1 MB and has been trimmed to fit the gist limit. Please check logs for the untrimmed issue." > trimmed_comment_gist.md
            fi
            head -c $ONE_MB_IN_BYTES "comment.md" >> trimmed_comment_gist.md
            if [ $FILE_SIZE -gt $ONE_MB_IN_BYTES ]; then
              printf "\nThe file was greater than 1 MB and has been trimmed to fit the gist limit. Please check logs for the untrimmed issue." >> trimmed_comment_gist.md
            fi
          fi
          printf "\n### Testsuite download links\n" >> trimmed_comment.md
          echo "Please check the Additional Information Build Targets section to see which testsuite log to look at. Do note that if you cannot download the artifacts, you may need to sign in to github first."
          cat gcc-*.md >> trimmed_comment.md
          echo "" >> trimmed_comment.md
          printf "\n[Additional information](${{ inputs.additional_info }})\n" >> trimmed_comment.md
          cat trimmed_comment.md

      - name: Create Unresolved Errors Comment Gist
        run: |
          if [ -e "trimmed_comment_gist.md" ]; then
            python3 ./scripts/create_gist.py --token ${{ secrets.GIST_TOKEN }} --input trimmed_comment_gist.md --output comment_gist_url.txt --title ${{ inputs.issue_num }}_${{ inputs.patch_name }}_${{ inputs.patch_applied_gcchash }}_summary.md
            printf "\nGist URL: $(cat comment_gist_url.txt)" >> trimmed_comment.md
          fi
        continue-on-error: true

      - name: Update test report comment
        uses: peter-evans/create-or-update-comment@v4
        id: test-report
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          comment-id: ${{ inputs.test_comment_id }}
          body-path: riscv-gnu-toolchain/trimmed_comment.md
          edit-mode: replace

      - name: Output issue labels
        id: issue-labels
        run: |
          export LABELS=$(cat labels.txt)
          echo "issue_labels=$LABELS" >> $GITHUB_OUTPUT

      - name: Add New regressions Label to Issue
        if: ${{ contains(steps.issue-labels.outputs.issue_labels, 'new-regressions') }}
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.addLabels({
              issue_number: ${{ inputs.issue_num }},
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['new-regressions']
            })

      - name: Add Resolved regressions Label to Issue
        if: ${{ contains(steps.issue-labels.outputs.issue_labels, 'resolved-regressions') }}
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.addLabels({
              issue_number: ${{ inputs.issue_num }},
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['resolved-regressions']
            })

      # Adds comment which links issue to PR
      - name: Link Staging PR
        uses: actions/github-script@v7
        if: ${{ github.workflow == 'Staging' && github.event.pull_request }}
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: ${{ inputs.issue_num }},
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'Pull request: ${{ github.event.pull_request.html_url }}'
            })

      - name: Report Failure
        if: ${{ github.workflow != 'Staging' && (contains(steps.issue-labels.outputs.issue_labels, 'build-failure') || contains(steps.issue-labels.outputs.issue_labels, 'testsuite-failure') || contains(steps.issue-labels.outputs.issue_labels, 'new-regressions')) }}
        id: report-failure
        run: |
          python scripts/post_check_to_patchworks.py -event ${{ github.event_name }} -repo ewlu/gcc-precommit-ci -pid $(tail -n 1 ./patches/${{ inputs.patch_name }}) -desc 'Testing failed' -iid '${{ inputs.issue_num }}#issuecomment-${{ inputs.test_comment_id }}' -state 'fail' -context 'test' -token '${{ secrets.PATCHWORK_API }}'
        continue-on-error: true

      - name: Report Success
        if: ${{ github.workflow != 'Staging' && steps.report-failure.outcome == 'skipped' }}
        id: report-success
        run: |
          python scripts/post_check_to_patchworks.py -event ${{ github.event_name }} -repo ewlu/gcc-precommit-ci -pid $(tail -n 1 ./patches/${{ inputs.patch_name }}) -desc 'Testing passed' -iid '${{ inputs.issue_num }}#issuecomment-${{ inputs.test_comment_id }}' -state 'success' -context 'test' -token '${{ secrets.PATCHWORK_API }}'
        continue-on-error: true
